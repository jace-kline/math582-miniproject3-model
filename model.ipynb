{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Math 582 Miniproject 3 - Model Development\n",
    "\n",
    "The purpose of this notebook is implment dual SVM convex quadratic optimization for the purposes of binary classification."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from qpsolvers import solve_qp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "source": [
    "# read in data\n",
    "df = pd.read_csv('./data/test-data/test_data.csv')\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>interest</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.657801</td>\n",
       "      <td>18.859917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.573729</td>\n",
       "      <td>17.969223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.553424</td>\n",
       "      <td>29.463651</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.718035</td>\n",
       "      <td>25.704665</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.401919</td>\n",
       "      <td>16.770856</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>27.697220</td>\n",
       "      <td>18.799309</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>15.150959</td>\n",
       "      <td>72.000352</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>22.264378</td>\n",
       "      <td>68.453459</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>25.677420</td>\n",
       "      <td>90.118212</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>21.215594</td>\n",
       "      <td>48.265520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age   interest  success\n",
       "0    23.657801  18.859917      0.0\n",
       "1    22.573729  17.969223      0.0\n",
       "2    32.553424  29.463651      0.0\n",
       "3     6.718035  25.704665      1.0\n",
       "4    14.401919  16.770856      0.0\n",
       "..         ...        ...      ...\n",
       "292  27.697220  18.799309      0.0\n",
       "293  15.150959  72.000352      1.0\n",
       "294  22.264378  68.453459      1.0\n",
       "295  25.677420  90.118212      1.0\n",
       "296  21.215594  48.265520      1.0\n",
       "\n",
       "[297 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 360
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "source": [
    "# This function performs the following:\n",
    "# - maps classifiers values -1 or +1\n",
    "# - separates feature columns from the classifier column\n",
    "# - splits the data into training and testing sets\n",
    "# returns: xs_train, xs_test, ys_train, ys_test\n",
    "\n",
    "def prep_data(df, classifier_column_name, classifier_vals, train_size=0.75):\n",
    "\n",
    "    if len(classifier_vals) != 2:\n",
    "        raise ValueError(\"classifier_vals argument must be length 2 (binary classifier)\")\n",
    "    \n",
    "    # map each binary classifier value to either 1 or -1\n",
    "    df[classifier_column_name] = df[classifier_column_name].apply(lambda b: -1 if b == classifier_vals[0] else 1)\n",
    "\n",
    "    # separate the features from the classifications\n",
    "    colnames = df.columns.tolist()\n",
    "    feature_column_names = list(filter(lambda colname: colname != classifier_column_name, colnames))\n",
    "\n",
    "    xs = df[feature_column_names]\n",
    "    ys = df[classifier_column_name]\n",
    "\n",
    "    # split the data into training and testing data\n",
    "    datasets = train_test_split(xs, ys, train_size=train_size)\n",
    "\n",
    "    # map all the training data into numpy arrays\n",
    "    xs_train, xs_test, ys_train, ys_test = list(map(lambda s: s.to_numpy(), datasets))\n",
    "\n",
    "    # return the training and testing data\n",
    "    return xs_train, xs_test, ys_train, ys_test\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "source": [
    "# compute the kernel matrix K\n",
    "def kernel_matrix(xs_train, k):\n",
    "    N = xs_train.shape[0]\n",
    "    K = np.zeros(shape=(N,N))\n",
    "    for i in range(0, N):\n",
    "        for j in range(0, i + 1):\n",
    "            K[i][j] = K[j][i] = k(xs_train[i], xs_train[j])\n",
    "    return K\n",
    "\n",
    "# assume A is an NxN matrix\n",
    "def make_positive_definite(A):\n",
    "    N = A.shape[0]\n",
    "    # if all eigenvals are not > 0, then add perturbation and try again\n",
    "    while not np.all(np.linalg.eigvals(A) > 0):\n",
    "        epsilon = 1e-10\n",
    "        perturbation = epsilon * np.identity(N)\n",
    "        A += perturbation\n",
    "    return A\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "source": [
    "# define the function used to get the optimal lagrange multipliers (alpha) for given training data, kernel function, and cost function\n",
    "def optimize(xs_train, ys_train, k, C):\n",
    "    N = xs_train.shape[0]\n",
    "\n",
    "    # compute the entries in the kernel matrix\n",
    "    K = make_positive_definite(kernel_matrix(xs_train, k))\n",
    "    Y = np.diag(ys_train)\n",
    "\n",
    "    # quadratic program parameters\n",
    "    P = Y @ K @ Y\n",
    "    q = np.ones(N)\n",
    "    G = np.vstack([ys_train, -1 * ys_train, -1 * np.identity(N), np.identity(N)])\n",
    "    h = np.concatenate([np.zeros((N+2)), C * np.ones((N))])\n",
    "\n",
    "    return solve_qp(P, q, G, h)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "source": [
    "def build_svm_classifier(xs_train, ys_train, k, C):\n",
    "    N = xs_train.shape[0]\n",
    "    alpha = optimize(xs_train, ys_train, k, C)\n",
    "\n",
    "    fw = lambda n: alpha[n] * ys_train[n] * xs_train[n]\n",
    "    w = np.array(list(reduce(lambda v1, v2: v1 + v2, list(map(fw, range(0, N))))))\n",
    "\n",
    "    fb = lambda n: np.abs(ys_train[n] - np.dot(w, xs_train[n]))\n",
    "    b = np.median(np.array(list(map(fb, range(0, N)))))\n",
    "\n",
    "    def classifier(xs_test):\n",
    "        return np.array(list(map(lambda x_test: 1 if np.dot(w, x_test) + b >= 0 else -1, list(xs_test))))\n",
    "\n",
    "    return classifier\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "source": [
    "def poly_kernel(d):\n",
    "    if d < 1:\n",
    "        raise ValueError(\"Invalid polynomial dimension for polynomial kernel\")\n",
    "\n",
    "    def inner(xi, xj):\n",
    "        return (1 + np.dot(xi, xj)) ** d\n",
    "\n",
    "    return inner"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "source": [
    "xs_train, xs_test, ys_train, ys_test = prep_data(df, \"success\", [0.0, 1.0], train_size=0.5)\n",
    "\n",
    "k = poly_kernel(2)\n",
    "C = 1\n",
    "classifier = build_svm_classifier(xs_train, ys_train, k, C)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26086/3002790807.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_svm_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_26086/3245509112.py\u001b[0m in \u001b[0;36mbuild_svm_classifier\u001b[0;34m(xs_train, ys_train, k, C)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_svm_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxs_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mys_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxs_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26086/489161620.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(xs_train, ys_train, k, C)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# compute the entries in the kernel matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_positive_definite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26086/2449147782.py\u001b[0m in \u001b[0;36mmake_positive_definite\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# if all eigenvals are not > 0, then add perturbation and try again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mperturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meigvals\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/installs/anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36meigvals\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         _raise_linalgerror_eigenvalues_nonconvergence)\n\u001b[1;32m   1067\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->D'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluate_classifier(classifier, xs_test, ys_test):\n",
    "    numtests = xs_test.shape[0]\n",
    "    results = classifier(xs_test) == ys_test\n",
    "    numcorrect = len(list(filter(lambda b: b, list(results))))\n",
    "    successrate = numcorrect / numtests\n",
    "    return successrate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "evaluate_classifier(classifier, xs_test, ys_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5369127516778524"
      ]
     },
     "metadata": {},
     "execution_count": 356
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "linsvc = SVC(kernel = 'polynomial', degree=2, C=C)\n",
    "linsvc.fit(xs_train, ys_train)\n",
    "evaluate_classifier(linsvc.predict, xs_test, ys_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8993288590604027"
      ]
     },
     "metadata": {},
     "execution_count": 357
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classifier(xs_test) == ys_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False, False, False,  True,\n",
       "        True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False,  True,  True, False, False,  True, False,\n",
       "        True, False,  True, False, False, False, False, False,  True,\n",
       "       False,  True, False, False, False,  True,  True,  True, False,\n",
       "       False, False, False, False,  True, False,  True,  True, False,\n",
       "       False,  True,  True, False, False,  True, False,  True, False,\n",
       "       False,  True, False, False, False, False,  True, False, False,\n",
       "        True, False, False,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True, False, False,  True,\n",
       "        True, False, False, False,  True, False,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False,  True, False, False, False,\n",
       "        True,  True,  True,  True, False,  True, False, False, False,\n",
       "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "       False, False, False,  True,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 358
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "779c798a75e127e3aa96660aebf9b74d3e571412428da99918dfc4cadf485d44"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}